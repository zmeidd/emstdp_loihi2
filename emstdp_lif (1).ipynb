{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2062acfa-84b6-478b-9b3c-e4261fca6342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers 2\n",
      "layer index 0\n",
      "layer index 1\n",
      "ethreshold = \n",
      "8\n",
      "(100, 10)\n",
      "(100, 200)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# !SLURM=1 LOIHI_GEN=N3B3 PARTITION=oheogulch_2h\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "from lava.magma.core.learning.learning_rule import Loihi2FLearningRule\n",
    "from lava.magma.core.learning.learning_rule import LoihiLearningRule\n",
    "from lava.proc.dense.process import LearningDense, Dense, DelayDense\n",
    "from lava.proc.lif.process import LIFReset\n",
    "from lava.utils.weightutils import SignMode\n",
    "from lava.magma.core.decorator import implements, tag, requires\n",
    "from lava.proc.dense.process import Dense\n",
    "\n",
    "from lava.magma.core.run_configs import Loihi2HwCfg ,Loihi2SimCfg\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.callback_fx import NxSdkCallbackFx\n",
    "from lava.proc.learning_rules.stdp_learning_rule import STDPLoihi\n",
    "from lava.proc.monitor.process import Monitor\n",
    "from lava.magma.core.learning.learning_rule import Loihi2FLearningRule\n",
    "from lava.proc.monitor.process import Monitor\n",
    "import time\n",
    "\n",
    "\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "\n",
    "class Lif(AbstractProcess):\n",
    "    \"\"\"Leaky-Integrate-and-Fire neural process with activation input and spike\n",
    "    output ports a_in and s_out.\n",
    "\n",
    "    Realizes the following abstract behavior:\n",
    "    u[t] = u[t-1] * (1-du) + a_in\n",
    "    v[t] = v[t-1] * (1-dv) + u[t] + bias\n",
    "    s_out = v[t] > vth\n",
    "    v[t] = v[t] - s_out*vth\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "       super().__init__(**kwargs)\n",
    "       shape = kwargs.get(\"shape\", (1,))\n",
    "       self.a_in = InPort(shape=shape)\n",
    "       self.s_out = OutPort(shape=shape)\n",
    "       self.u = Var(shape=shape, init=0)\n",
    "       self.v = Var(shape=shape, init=0)\n",
    "       self.du = Var(shape=(1,), init=kwargs.pop(\"du\", 0))\n",
    "       self.dv = Var(shape=(1,), init=kwargs.pop(\"dv\", 0))\n",
    "       self.bias_mant = Var(shape=shape, init=kwargs.pop(\"bias_mant\", 0))\n",
    "       self.bias_exp = Var(shape=shape, init=kwargs.pop(\"bias_exp\", 0))\n",
    "       self.vmin_exp = Var(shape=shape, init=kwargs.pop(\"vmin_exp\", 23))\n",
    "       self.vmax_exp = Var(shape=shape, init=kwargs.pop(\"vmax_exp\", 23))\n",
    "       self.vth = Var(shape=(1,), init=kwargs.pop(\"vth\", 64))\n",
    "        \n",
    "    def set_vth(self,value):\n",
    "        self.vth = value\n",
    "\n",
    "    def set_dv(self,value):\n",
    "        self.dv = value\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "from lava.proc.lif.process import LIF\n",
    "\n",
    "\n",
    "@implements(proc=Lif, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "@tag('fixed_pt')\n",
    "class PyLifModel(PyLoihiProcessModel):\n",
    "    a_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, np.int16, precision=16)\n",
    "    s_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "    u: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    v: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    bias_mant: np.ndarray = LavaPyType(np.ndarray, np.int16, precision=12)\n",
    "    bias_exp: np.ndarray = LavaPyType(np.ndarray, np.int16, precision=12)\n",
    "    du: int = LavaPyType(int, np.uint16, precision=12)\n",
    "    dv: int = LavaPyType(int, np.uint16, precision=12)\n",
    "    vmin_exp: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    vmax_exp: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=24)\n",
    "    vth: int = LavaPyType(int, int, precision=8)\n",
    "\n",
    "    def run_spk(self):\n",
    "        bias = self.bias_mant*2**self.bias_exp\n",
    "        self.u[:] = self.u * ((2 ** 12 - self.du) // 2 ** 12)\n",
    "        a_in_data = 2**6*self.a_in.recv()\n",
    "        self.u[:] += a_in_data\n",
    "        self.v[:] = self.v * ((2 ** 12 - self.dv) // 2 ** 12) + (self.u) + bias\n",
    "        #rescale voltage\n",
    "        s_out = self.v >self.vth\n",
    "\n",
    "        min = -2**self.vmin_exp+1\n",
    "        #determine the minimum voltage\n",
    "        self.v[self.v < -1] = -1\n",
    "\n",
    "        \n",
    "        self.v[s_out] = 0  # Reset voltage to 0. This is Loihi-1 compatible.\n",
    "        self.s_out.send(s_out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SELECT_TAG = \"fixed_pt\"\n",
    "\n",
    "#convert fixed point paras to floating point settings\n",
    "def converter(du,dv,vth):\n",
    "    vth = vth*2**6\n",
    "    return du,dv,vth\n",
    "    \n",
    "\n",
    "\n",
    "def init_wgts(wmin, wmax, wdes, wsrc, sd):\n",
    "    # np.random.seed((sd+1)*10)\n",
    "\n",
    "    tmpp = np.random.normal(0, np.sqrt(3.0 / float(wsrc)), [wdes, wsrc])\n",
    "\n",
    "    # wgts = tmpp * wmax\n",
    "\n",
    "    # wm = np.max(tmpp)\n",
    "    # wgts = tmpp * float(wmax/wm)\n",
    "    # wgts = np.clip(wgts, -255, 255)\n",
    "\n",
    "    amx = np.max(tmpp)\n",
    "    amn = np.min(tmpp)\n",
    "    a1 = (tmpp - amn) / (amx - amn)\n",
    "    a1 = a1 * (wmax - wmin) + wmin\n",
    "    wgts = np.clip(a1, a_min=wmin, a_max=wmax)\n",
    "\n",
    "    # wgts = np.random.randint(low=wmin, high=wmax, size=(wdes, wsrc))\n",
    "\n",
    "    wgts = wgts.astype(int)\n",
    "\n",
    "    return wgts\n",
    "\n",
    "\n",
    "def init_th(wsrc, layer, scale, wmax):\n",
    "    hThr = float(scale/(1)) * wmax * wsrc * (np.sqrt(3.0 / float(wsrc)) / (2.0))\n",
    "    # hThr = float(scale) * wmax * wsrc * (np.sqrt(3.0 / float(wsrc)) / (2.0))\n",
    "    #     hThr = float(scale / (layer + 1)) * wmax * wsrc * 1.0 * 0.5\n",
    "    hThr = int(hThr)\n",
    "    return hThr\n",
    "\n",
    "\n",
    "class emstdp:\n",
    "    def __init__(self,\n",
    "                 numInputs = 200,\n",
    "                 numHidNurns = [100,10],\n",
    "                 num_steps = 128\n",
    "                 ):\n",
    "        # make sure the type of the parameters class\n",
    "        # copy the parameters\n",
    "\n",
    "\n",
    "\n",
    "        self.stim2bias = [int(1) for i in range(1)]\n",
    "        self.stim2bias += [int(i * 1) for i in range(1, 256, 1)]\n",
    "        self.train_data = []\n",
    "        self.train_label = []\n",
    "        self.numHidNurns =  numHidNurns\n",
    "        self.numlayers = len(self.numHidNurns)\n",
    "        self.numInputs = numInputs\n",
    "        self.numMCs = self.numInputs\n",
    "        self.numTargets = 10\n",
    "        '''\n",
    "        GC is the intermediate layer neurons\n",
    "        '''\n",
    "        self.numHidNurns = numHidNurns\n",
    "        self.numGCs = np.sum(self.numHidNurns)\n",
    "\n",
    "\n",
    "        # self.poswgtrng = 48\n",
    "        # self.negwgtrng = -96\n",
    "\n",
    "        # self.bposwgtrng = 48\n",
    "        # self.bnegwgtrng = -96\n",
    "\n",
    "        self.poswgtrng = 128\n",
    "        self.negwgtrng = -128\n",
    "\n",
    "        self.bposwgtrng = 255\n",
    "        self.bnegwgtrng = -255\n",
    "        \n",
    "        # self.poswgtrng = 64\n",
    "        # self.negwgtrng = -64\n",
    "\n",
    "        # self.bposwgtrng = 128\n",
    "        # self.bnegwgtrng = -128\n",
    "        \n",
    "        self.inputs = []\n",
    "        \n",
    "        self.ec_pos =[[None],[None]]\n",
    "        self.ec_neg = [[None],[None]]\n",
    "        self.ec_tmp_pos =[[None],[None]]\n",
    "        self.ec_tmp_neg = [[None],[None]]\n",
    "        \n",
    "        self.ec_pos_aux = [[None],[None]]\n",
    "        self.ec_neg_aux = [[None],[None]]\n",
    "\n",
    "        # probes related data structures\n",
    "        self.allMCSomaProbes = None\n",
    "        self.exc2InhConnProbes = None\n",
    "        self.inh2ExcConnProbesPos = None\n",
    "        self.inh2ExcConnProbesNeg = None\n",
    "        self.mcADProbes = None\n",
    "        self.mcSomaProbes = None\n",
    "        self.gcProbes = None\n",
    "        self.label = None\n",
    "        self.numStepsRan = 0\n",
    "        self.wgt_exp = dict()\n",
    "\n",
    "        #weights for testing use\n",
    "        self.hid_wgt = []\n",
    "        self.out_wgt = []\n",
    "\n",
    "        #testing usage\n",
    "        self.test_inter = []\n",
    "        self.test_out = []\n",
    "        self.test_connections = []\n",
    "        #probes\n",
    "        self.out_probe = []\n",
    "\n",
    "        \n",
    "    def setupNetwork(self, train, wgt, bwgt):\n",
    "        \"\"\" setups the EPL network \"\"\"\n",
    "\n",
    "        if train:\n",
    "            self.trainbool = 1\n",
    "        else:\n",
    "            self.trainbool = 0\n",
    "\n",
    "        self.allMCSomaGrp = None\n",
    "        self.allLabelGrp = None\n",
    "        self.wtaGrp = None\n",
    "\n",
    "        self.allGCsPerPattern = dict()\n",
    "        self.allPosECsPerPattern = dict()\n",
    "        self.pos_ec_soma = None\n",
    "        self.pos_ec_denrite = None\n",
    "        self.allNegECsPerPattern = dict()\n",
    "        self.neg_ec_soma = None\n",
    "        self.neg_ec_dendrite = None\n",
    "        self.allTmpPosECsPerPattern = dict()\n",
    "        self.allTmpNegECsPerPattern = dict()\n",
    "\n",
    "        self.forwardConns = dict()\n",
    "        self.posbackwardConns = dict()\n",
    "        self.negbackwardConns = dict()\n",
    "        self.hiddens = dict()\n",
    "\n",
    "        '''\n",
    "        Create input patterns\n",
    "        '''\n",
    "        self.createMCNeurons()\n",
    "\n",
    "        '''\n",
    "        create label layer\n",
    "        '''\n",
    "        # du,dv,vth = converter(4095,0,2)\n",
    "        self.allLabelGrp = self.create_cx(patternIdx= -1,du=int(4095),dv=0,vth=2,name = \"label\")\n",
    "\n",
    "        print(\"number of layers\", self.numlayers)\n",
    "\n",
    "        for patternIdx in range(self.numlayers):\n",
    "            '''\n",
    "            Hidden layers\n",
    "            ''' \n",
    "            \n",
    "            self.inhid_vth = 0.5 #0.3 # first layer threshold\n",
    "            self.hid_vth = 0.3 # middle layer threshold\n",
    "            self.classifier_vth = 0.3 # 0.5 # classifier layer threshold\n",
    "            self.biasEx = 0 # bias exponential\n",
    "            self.biasMn = 0 # bias mantissa default\n",
    "\n",
    "            scale = 1\n",
    "            self.GCtoECDelayDeriv = int(10)\n",
    "            # self.ECtoGCDelayDeriv = int(2)\n",
    "            self.wtadelay = int(0)\n",
    "            # self.lastECdelay = int(0)\n",
    "            self.voldcy = int(0)\n",
    "            self.curdcy = int(4000)\n",
    "\n",
    "\n",
    "            self.ECtoGCwgt = 255\n",
    "            self.LabeltoECwgt = 8\n",
    "\n",
    "            thold = 0\n",
    "            wsrc = 0\n",
    "            \n",
    "            # calculating forward and error path thresholds\n",
    "            if patternIdx == self.numlayers - 1:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.classifier_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(self.LabeltoECwgt)\n",
    "            elif patternIdx == 0:\n",
    "                wsrc = self.numMCs\n",
    "                thold = init_th(wsrc, patternIdx, self.inhid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                if self.numlayers == 2:\n",
    "                    ethold = int(self.LabeltoECwgt)\n",
    "                else:\n",
    "                    ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.inhid_vth, 255) / (patternIdx + 2))\n",
    "                    # ethold = int(self.LabeltoECwgt) + (self.numlayers - patternIdx - 2)*ethold\n",
    "            else:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.hid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.hid_vth, 255) / (patternIdx + 2))\n",
    "            numTmps = int(np.ceil(thold / 255))\n",
    "            # weight exponential from intermediate error neurons to forward path\n",
    "            ijexp = int(np.ceil(np.log2(numTmps)) + 1)\n",
    "            # weight exponenital\n",
    "            self.wgt_exp[patternIdx] = ijexp\n",
    "\n",
    "            if patternIdx != self.numlayers - 1:\n",
    "                # self.allPosECsPerPattern[patternIdx] = self.net.createNeuronGroup()\n",
    "                # self.allNegECsPerPattern[patternIdx] = self.net.createNeuronGroup()\n",
    "                # self.allTmpPosECsPerPattern[patternIdx] = self.net.createCompartmentGroup()\n",
    "                # self.allTmpNegECsPerPattern[patternIdx] = self.net.createCompartmentGroup()\n",
    "                '''\n",
    "                initialize posEC, negEC, tmp PosEC, tmp negEC\n",
    "                posEC_soma: soma_du = 4095,soma_dv=0, bias_mant =0, vth =ethod\n",
    "                pos_ec_denrite: du= 0, dv= 0, vth =2,\n",
    "                \n",
    "                negEC soma: du= 4095 ,dv=0 , vth = ehold,\n",
    "                negEC dendrite: \n",
    "                '''\n",
    "                # pos ec\n",
    "                # self.allPosECsPerPattern[patternIdx] = andSoma(shape = self.numHidNurns[patternIdx])\n",
    "                self.allPosECsPerPattern[patternIdx] = self.create_cx(patternIdx =patternIdx,\n",
    "                                                                      du = 4095,\n",
    "                                                                      dv = 4095,\n",
    "                                                                      vth = 3,\n",
    "                                                                      name = \"POS_EC_\"+str(patternIdx)\n",
    "                                                                     )\n",
    "                self.pos_ec_soma = self.create_cx(patternIdx =patternIdx,\n",
    "                                                  du=4095,\n",
    "                                                  dv=0,\n",
    "                                                  vth = ethold,\n",
    "                                                  vmin_exp= 10,\n",
    "                                                  name = \"pos_ec_soma_\"+str(patternIdx))\n",
    "                self.pos_ec_dendrite = self.create_cx(patternIdx = patternIdx,\n",
    "                                                      du=0,\n",
    "                                                      dv=0,\n",
    "                                                      vth =2,\n",
    "                                                      vmin_exp=10,\n",
    "                                                     name = \"pos_ec_dendrite_\" + str(patternIdx))\n",
    "                # neg ec\n",
    "                # self.allNegECsPerPattern[patternIdx] = andSoma(shape = self.numHidNurns[patternIdx])\n",
    "                self.allNegECsPerPattern[patternIdx] = self.create_cx(patternIdx =patternIdx,\n",
    "                                                                      du = 4095,\n",
    "                                                                      dv = 4095,\n",
    "                                                                      vth = 3,\n",
    "                                                                     name = \"NEG_EC\"+str(patternIdx)\n",
    "                                                                     )\n",
    "                self.neg_ec_soma= self.create_cx(patternIdx = patternIdx, \n",
    "                                                 du=4095,\n",
    "                                                 dv=0, \n",
    "                                                 vth = ethold,\n",
    "                                                 vmin_exp= 10,\n",
    "                                                 name = \"neg_ec_soma_\"+str(patternIdx))\n",
    "                self.neg_ec_dendrite = self.create_cx(patternIdx= patternIdx,\n",
    "                                                      du=0,\n",
    "                                                      dv=0,\n",
    "                                                      vth =2,\n",
    "                                                      vmin_exp= 10,\n",
    "                                                      name = \"neg_ec_dendrite_\" + str(patternIdx)\n",
    "                                                      )\n",
    "                \n",
    "\n",
    "            else:\n",
    "                '''\n",
    "                du =0 , dv =0, vth =2,\n",
    "                '''\n",
    "                self.allPosECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx, \n",
    "                                                                      du =4095,\n",
    "                                                                      dv =0 ,\n",
    "                                                                      vth =ethold,\n",
    "                                                                      vmin_exp= 10,\n",
    "                                                                      name = \"POS_EC_\"+str(patternIdx)\n",
    "                                                                     )\n",
    "            \n",
    "                self.allNegECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx, \n",
    "                                                                      du =4095, \n",
    "                                                                      dv =0 ,\n",
    "                                                                      vth =ethold,\n",
    "                                                                      vmin_exp= 10,\n",
    "                                                                      name = \"NEG_EC_\"+str(patternIdx)\n",
    "                                                                     )\n",
    "                \n",
    "            '''\n",
    "            ec tmp pos: du =4095, dv =0, vthMant = 2\n",
    "            ec tmp neg: du= 4095, dv =0, vthMant = 2\n",
    "            '''\n",
    "            self.allTmpPosECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx,\n",
    "                                                                     du =4095,\n",
    "                                                                     dv=0 ,\n",
    "                                                                     vth =2,\n",
    "                                                                     vmin_exp= 10,\n",
    "                                                                     name = \"tmp_pos_ec_\" +str(patternIdx)\n",
    "                                                                    )\n",
    "            self.allTmpNegECsPerPattern[patternIdx] = self.create_cx(patternIdx= patternIdx, \n",
    "                                                                     du =4095, \n",
    "                                                                     dv=0,\n",
    "                                                                     vth =2,\n",
    "                                                                     vmin_exp= 10,\n",
    "                                                                     name = \"tmp_pos_ec_\" +str(patternIdx))\n",
    "            #create GC neurons per pattern\n",
    "            print(\"layer index\", patternIdx)\n",
    "            self.createGCNeuronsPerPattern(patternIdx)\n",
    "\n",
    "        self.connectforwardConns(train, wgt)\n",
    "        self.connectbackwardConns(bwgt)\n",
    "\n",
    "    def create_cx(self,patternIdx, du,dv,vth,name,bias_mant =0, \n",
    "                   bias_exp =0,vmin_exp = 23,vmax_exp = 23):\n",
    "        du,dv,vth = converter(du,dv,vth)\n",
    "        return Lif(shape = (self.numHidNurns[patternIdx],),\n",
    "                   du = du,\n",
    "                   dv = dv,\n",
    "                   vth = vth,\n",
    "                   bias_mant = bias_mant,\n",
    "                   bias_exp = bias_exp,\n",
    "                   vmin_exp = vmin_exp,\n",
    "                   name = name\n",
    "                   )\n",
    "    def createTestGC(self, patternIdx):\n",
    "                \n",
    "            self.inhid_vth = 0.5 #0.3 # first layer threshold\n",
    "            self.hid_vth = 0.3 # middle layer threshold\n",
    "            self.classifier_vth = 0.3 # 0.5 # classifier layer threshold\n",
    "            self.biasEx = 0 # bias exponential\n",
    "            self.biasMn = 0 # bias mantissa default\n",
    "\n",
    "            scale = 1\n",
    "            self.GCtoECDelayDeriv = int(10)\n",
    "            # self.ECtoGCDelayDeriv = int(2)\n",
    "            self.wtadelay = int(0)\n",
    "            # self.lastECdelay = int(0)\n",
    "            self.voldcy = int(0)\n",
    "            self.curdcy = int(4000)\n",
    "\n",
    "            self.wtadelay = int(0)\n",
    "\n",
    "            self.ECtoGCwgt = 255\n",
    "            self.LabeltoECwgt = 8\n",
    "\n",
    "            thold = 0\n",
    "            wsrc = 0\n",
    "            \n",
    "            # calculating forward and error path thresholds\n",
    "            if patternIdx == self.numlayers - 1:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.classifier_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(self.LabeltoECwgt)\n",
    "                print(\"ethreshold = \")\n",
    "                print(ethold)\n",
    "            elif patternIdx == 0:\n",
    "                wsrc = self.numMCs\n",
    "                thold = init_th(wsrc, patternIdx, self.inhid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                if self.numlayers == 2:\n",
    "                    ethold = int(self.LabeltoECwgt)\n",
    "                else:\n",
    "                    ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.inhid_vth, 255) / (patternIdx + 2))\n",
    "\n",
    "            else:\n",
    "                wsrc = self.numHidNurns[patternIdx - 1]\n",
    "                thold = init_th(wsrc, patternIdx, self.hid_vth, 255)\n",
    "                self.biasMn = int(thold / 10)\n",
    "                ref = 1\n",
    "                ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.hid_vth, 255) / (patternIdx + 2))\n",
    "            \n",
    "            \n",
    "            # du,dv,vth = converter(self.curdcy,self.voldcy,thold)\n",
    "            self.hiddens[patternIdx] =self.create_cx(patternIdx = patternIdx,\n",
    "                                                            du = self.curdcy,dv= self.voldcy,vth = thold,\n",
    "                                                            bias_mant= self.biasMn,\n",
    "                                                            bias_exp = self.biasEx,\n",
    "                                                            vmin_exp= 20,\n",
    "                                                            name = 'fwd_layer'+str(patternIdx)\n",
    "                                                        \n",
    "                                                            )\n",
    "            \n",
    "    #create input neurons\n",
    "    def createMCNeurons(self, biasMant=0):\n",
    "        du =0\n",
    "        dv =0\n",
    "        vth =4*4\n",
    "        du,dv,vth = converter(du,dv,vth)\n",
    "        '''\n",
    "        input neurons\n",
    "        '''\n",
    "        mcSomaCx = Lif(\n",
    "            shape = (self.numMCs,),\n",
    "            du =du,\n",
    "            dv = dv,\n",
    "            vth = vth,\n",
    "            vmin_exp = 0,\n",
    "            name = \"train\"\n",
    "        )\n",
    "        self.allMCSomaGrp = mcSomaCx\n",
    "    #create input neurons\n",
    "    def createTestInputs(self, biasMant=0):\n",
    "        du =0\n",
    "        dv =0\n",
    "        vth =4*4\n",
    "        du,dv,vth = converter(du,dv,vth)\n",
    "        '''\n",
    "        input neurons\n",
    "        '''\n",
    "        test_mc =Lif(\n",
    "            shape = (self.numMCs,),\n",
    "            du =du,\n",
    "            dv = dv,\n",
    "            vth = vth,\n",
    "            vmin_exp = 0,\n",
    "            name = \"test\"\n",
    "        )\n",
    "        self.inputs = test_mc\n",
    "        \n",
    "    def createGCNeuronsPerPattern(self, patternIdx):\n",
    "            \n",
    "        self.inhid_vth = 0.5 #0.3 # first layer threshold\n",
    "        self.hid_vth = 0.3 # middle layer threshold\n",
    "        self.classifier_vth = 0.3 # 0.5 # classifier layer threshold\n",
    "        self.biasEx = 2 # bias exponential\n",
    "        self.biasMn = 1 # bias mantissa default\n",
    "\n",
    "        scale = 1\n",
    "        self.GCtoECDelayDeriv = int(10)\n",
    "        # self.ECtoGCDelayDeriv = int(2)\n",
    "        self.wtadelay = int(0)\n",
    "        # self.lastECdelay = int(0)\n",
    "        self.voldcy = int(0)\n",
    "        self.curdcy = int(4000)\n",
    "\n",
    "        self.wtadelay = int(0)\n",
    "\n",
    "        self.ECtoGCwgt = 255\n",
    "        self.LabeltoECwgt = 8\n",
    "\n",
    "        thold = 0\n",
    "        wsrc = 0\n",
    "        \n",
    "        # calculating forward and error path thresholds\n",
    "        if patternIdx == self.numlayers - 1:\n",
    "            wsrc = self.numHidNurns[patternIdx - 1]\n",
    "            thold = init_th(wsrc, patternIdx, self.classifier_vth, 255)\n",
    "            self.biasMn = int(thold / 10)\n",
    "            ref = 1\n",
    "            ethold = int(self.LabeltoECwgt)\n",
    "            print(\"ethreshold = \")\n",
    "            print(ethold)\n",
    "        elif patternIdx == 0:\n",
    "            wsrc = self.numMCs\n",
    "            thold = init_th(wsrc, patternIdx, self.inhid_vth, 255)\n",
    "            self.biasMn = int(thold / 10)\n",
    "            ref = 1\n",
    "            if self.numlayers == 2:\n",
    "                ethold = int(self.LabeltoECwgt)\n",
    "            else:\n",
    "                ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.inhid_vth, 255) / (patternIdx + 2))\n",
    "\n",
    "        else:\n",
    "            wsrc = self.numHidNurns[patternIdx - 1]\n",
    "            thold = init_th(wsrc, patternIdx, self.hid_vth, 255)\n",
    "            self.biasMn = int(thold / 10)\n",
    "            ref = 1\n",
    "            ethold = int(init_th(self.numHidNurns[patternIdx + 1], patternIdx, self.hid_vth, 255) / (patternIdx + 2))\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.allGCsPerPattern[patternIdx] =self.create_cx(patternIdx = patternIdx,\n",
    "                                                          du = self.curdcy,dv=self.voldcy,\n",
    "                                                          vth = thold, \n",
    "                                                          bias_mant= self.biasMn,\n",
    "                                                          bias_exp = self.biasEx,\n",
    "                                                          vmax_exp=20,\n",
    "                                                          name = \"gc_layer_\"+str(patternIdx))\n",
    "        \n",
    "\n",
    "        # creating connections from the error network to the forward path\n",
    "        # hidden layer connections\n",
    "        if patternIdx != self.numlayers - 1:\n",
    "            \n",
    "            posECtoTmpEC_conn = Dense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "\n",
    "            '''\n",
    "            to do connection 1: pos ec soma -> tmp pos ec\n",
    "            weight = 10\n",
    "            '''\n",
    "            # pos_ec to tmp ec\n",
    "            # src: pos ec soma\n",
    "            # dst: tmp pos ec \n",
    "            self.allPosECsPerPattern[patternIdx].s_out.connect(posECtoTmpEC_conn.s_in)\n",
    "            posECtoTmpEC_conn.a_out.connect(self.allTmpPosECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 2: neg ec soma-> tmp neg ec \n",
    "            weight = 10\n",
    "            '''\n",
    "            negECtoTmpEC_conn = Dense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allNegECsPerPattern[patternIdx].s_out.connect(negECtoTmpEC_conn.s_in)\n",
    "            negECtoTmpEC_conn.a_out.connect(self.allTmpNegECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 3: \n",
    "            src tmp pos EC-> dst gc(forward)\n",
    "            weights: self.ECtoGCwgt\n",
    "            weight_exp: ijexp\n",
    "            '''\n",
    "            tmpPosECtoGCconns = Dense(\n",
    "                weights = self.ECtoGCwgt*(np.eye(self.numHidNurns[patternIdx]).astype(int))\n",
    "            )\n",
    "            self.allTmpPosECsPerPattern[patternIdx].s_out.connect(tmpPosECtoGCconns.s_in)\n",
    "            tmpPosECtoGCconns.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 4:\n",
    "            src tmp neg ec-> gc\n",
    "            weight: -self.ECtoGCwgt\n",
    "            weight_exp: ijexp\n",
    "            '''\n",
    "            tmpnegECtoGCConns = Dense (\n",
    "                weights = -self.ECtoGCwgt*(np.eye(self.numHidNurns[patternIdx]).astype(int)))\n",
    "            self.allTmpNegECsPerPattern[patternIdx].s_out.connect(tmpnegECtoGCConns.s_in)\n",
    "            tmpnegECtoGCConns.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            \n",
    "            ##########################\n",
    "            # creating connections from the forward path to auxilary error compartments to perform the derivative\n",
    "            '''\n",
    "            to do connection 5:\n",
    "            using delay dense here:\n",
    "            postSynResponseMode=nx.SYNAPSE_POST_SYN_RESPONSE_MODE.BOX, current remain a constant.\n",
    "            weight = 10, np eye\n",
    "            src GC -> dst pos EC dendrite[0]\n",
    "            \n",
    "            '''\n",
    "            posGCtoECConns = DelayDense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx]).astype(int),\n",
    "                delays = self.GCtoECDelayDeriv\n",
    "            )\n",
    "            \n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(posGCtoECConns.s_in)\n",
    "            posGCtoECConns.a_out.connect(self.pos_ec_dendrite.a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 6:\n",
    "            DenseDelay\n",
    "            weight =10,\n",
    "            src GC -> dst neg EC dendrite[0]\n",
    "            '''\n",
    "            negGCtoECConns = DelayDense(\n",
    "                weights = 10*np.eye(self.numHidNurns[patternIdx]).astype(int),\n",
    "                delays = self.GCtoECDelayDeriv\n",
    "            )\n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(negGCtoECConns.s_in)\n",
    "            negGCtoECConns.a_out.connect(self.neg_ec_dendrite.a_in)\n",
    "\n",
    "        # for classifier layer\n",
    "        if patternIdx == self.numlayers - 1:\n",
    "            \n",
    "          ########################################################\n",
    "            # loss computation through spikes at the top layer of error path using connections from classifier and label\n",
    "            labelscale = 1.5\n",
    "            gcscale = 2\n",
    "\n",
    "            \n",
    "            '''\n",
    "            to do connection 7\n",
    "            weight: -int(self.LabeltoECwgt * gcscale), np eye\n",
    "            src GC-> dst pos EC\n",
    "            '''\n",
    "            GCtoPosECConn = Dense(\n",
    "                weights = -int(self.LabeltoECwgt * gcscale)*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(GCtoPosECConn.s_in)\n",
    "            GCtoPosECConn.a_out.connect(self.allPosECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 8\n",
    "            weights: int(self.LabeltoECwgt * labelscale), np eye\n",
    "            src label -> dst pos ec\n",
    "            '''\n",
    "            LabeltoPosECConn = Dense(\n",
    "                weights = int(self.LabeltoECwgt * labelscale)*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allLabelGrp.s_out.connect(LabeltoPosECConn.s_in)\n",
    "            LabeltoPosECConn.a_out.connect(self.allPosECsPerPattern[patternIdx].a_in)\n",
    "            '''\n",
    "            to do connection 9:\n",
    "            src GC -> dst neg EC\n",
    "            weights: int(self.LabeltoECwgt * labelscale) np eye\n",
    "            '''\n",
    "            GCtoNegECConn = Dense(\n",
    "                            weights = int(self.LabeltoECwgt * labelscale)*np.eye(self.numHidNurns[patternIdx])     \n",
    "             )\n",
    "            self.allGCsPerPattern[patternIdx].s_out.connect(GCtoNegECConn.s_in)\n",
    "            GCtoNegECConn.a_out.connect(self.allNegECsPerPattern[patternIdx].a_in)\n",
    "\n",
    "            '''\n",
    "            to do connection 10:\n",
    "            weights: -int(self.LabeltoECwgt * gcscale) np.eye(self.numHidNurns[patternIdx])\n",
    "            src  label -> dst neg EC\n",
    "            \n",
    "            '''\n",
    "            LabeltoNegECConn  = Dense(\n",
    "                weights = -int(self.LabeltoECwgt * gcscale)*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allLabelGrp.s_out.connect(LabeltoNegECConn.s_in)\n",
    "            LabeltoNegECConn.a_out.connect(self.allNegECsPerPattern[patternIdx].a_in)\n",
    "            '''\n",
    "            to do connection 11:\n",
    "            weights: 10\n",
    "            connMAT\n",
    "            src pos EC -> dst tmp pos EC\n",
    "            '''\n",
    "            posECtoTmpPosEC = Dense(\n",
    "                weights = int(10)*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allPosECsPerPattern[patternIdx].s_out.connect(posECtoTmpPosEC.s_in)\n",
    "            posECtoTmpPosEC.a_out.connect(self.allTmpPosECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 12:\n",
    "            weights: 10\n",
    "            cnnMAT,\n",
    "            src  neg EC -> dst tmp neg EC\n",
    "            '''\n",
    "            negECtoTmpNegEC = Dense(\n",
    "                weights = int(10)*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allNegECsPerPattern[patternIdx].s_out.connect(negECtoTmpNegEC.s_in)\n",
    "            negECtoTmpNegEC.a_out.connect(self.allTmpNegECsPerPattern[patternIdx].a_in)\n",
    "            \n",
    "            '''\n",
    "            to do connection 13\n",
    "            weights: int(self.ECtoGCwgt / 1) connMAT\n",
    "            weight_exp: ijexp\n",
    "            src tmp pos EC -> dst GC\n",
    "            '''\n",
    "            tmpPosECtoGC = Dense(\n",
    "                weights =int(self.ECtoGCwgt / 1)*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allTmpPosECsPerPattern[patternIdx].s_out.connect(tmpPosECtoGC.s_in)\n",
    "            tmpPosECtoGC.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "            '''\n",
    "            to do connection 14:\n",
    "            weights: -int(self.ECtoGCwgt / 1)\n",
    "            weight_exp: ijexp\n",
    "            src tmp neg EC -> dst GC\n",
    "            '''\n",
    "            tmpnegEctoGC = Dense(\n",
    "                weights =-int(self.ECtoGCwgt / 1)*np.eye(self.numHidNurns[patternIdx])\n",
    "            )\n",
    "            self.allTmpNegECsPerPattern[patternIdx].s_out.connect(tmpnegEctoGC.s_in)\n",
    "            tmpnegEctoGC.a_out.connect(self.allGCsPerPattern[patternIdx].a_in)\n",
    "\n",
    "    def connectforwardConns(self, train, wgt):\n",
    "        \"\"\" creates the GC->MC inhibitory connections for each pattern\"\"\"\n",
    "        lr = 4  # 2^-lr learning rate\n",
    "        lrt = lr + 1  # top layer learning rate\n",
    "        lp = 7  # u7 -> 2^7 learning period\n",
    "\n",
    "        top_x1TimeConstant = 64\n",
    "        top_y1TimeConstant = 64\n",
    "\n",
    "        hid_x1TimeConstant = 64\n",
    "        hid_y1TimeConstant = 64\n",
    "\n",
    "        dw_top = '2^-' + str(lrt) + '*u' + str(lp) + '*y1*x1 - 2^-' + str(lrt + 1) + '*u' + str(lp) + '*t*x1'\n",
    "        dw_hid = '2^-' + str(lr) + '*u' + str(lp) + '*y1*x1 - 2^-' + str(lr + 1) + '*u' + str(lp) + '*t*x1'\n",
    "\n",
    "        for pIdx in range(self.numlayers):\n",
    "            if pIdx == self.numlayers - 1:\n",
    "                # single update per sample\n",
    "                # lr = self.net.createLearningRule(\n",
    "                #     dd='2^0*x0 - 2^3*u7*d',\n",
    "                #     dt='2^0*y0 - 2^0*u7*t',\n",
    "                #     dw='2^-6*u7*y1*x1 - 2^-7*u7*t*x1', \n",
    "                #     x1Impulse=1,\n",
    "                #     x1TimeConstant=32,\n",
    "                #     y1Impulse=1,\n",
    "                #     y1TimeConstant=128,\n",
    "                #     y2Impulse=1,\n",
    "                #     y2TimeConstant=4095,\n",
    "                #     tEpoch=1)\n",
    "            #     lr = Loihi2FLearningRule(\n",
    "            #         dd='2^0*x0 - 2^3*u7*d',\n",
    "            #         dt='2^0*y0 - 2^0*u7*t',\n",
    "            #         dw='2^-6*u7*y1*x1 - 2^-7*u7*t*x1',\n",
    "            #         x1_impulse = 1,\n",
    "            #         x1_tau = 32,\n",
    "            #         y1_impulse = 1,\n",
    "            #         y1_tau =128,\n",
    "            #         y2_impulse = 1,\n",
    "            #         y2_tau=4095,\n",
    "            #         t_epoch =1 \n",
    "            #     )\n",
    "            #     #dw='2^-5*u7*y1*x1 - 2^-6*u7*t*x1' for MSTAR works better\n",
    "            # else:\n",
    "            #     # single update per sample\n",
    "            #     lr = Loihi2FLearningRule(\n",
    "            #         dd='2^0*x0 - 2^3*u7*d',\n",
    "            #         dt='2^0*y0 - 2^0*u7*t',\n",
    "            #         dw='2^-5*u7*y1*x1 - 2^-6*u7*t*x1',\n",
    "            #         x1_impulse = 1,\n",
    "            #         x1_tau = 32,\n",
    "            #         y1_impulse = 1,\n",
    "            #         y1_tau =128,\n",
    "            #         y2_impulse = 1,\n",
    "            #         y2_tau=4000,\n",
    "            #         t_epoch=1)\n",
    "            \n",
    "            # if pIdx == self.numlayers - 1:\n",
    "                # single update per sample\n",
    "                lr = Loihi2FLearningRule(\n",
    "                    # dd='2^0*x0 - 2^3*u7*d',\n",
    "                    dt='2^0*y0 - 2^0*u7*t',\n",
    "                    dw=dw_top,  # add decay term\n",
    "                    x1_impulse=1,\n",
    "                    x1_tau=top_x1TimeConstant,\n",
    "                    y1_impulse=1,\n",
    "                    y1_tau=top_y1TimeConstant,\n",
    "                    x2_impulse=1,\n",
    "                    x2_tau=64,\n",
    "                    t_epoch=1)\n",
    "            elif pIdx == 0:\n",
    "                # single update per sample\n",
    "                lr = Loihi2FLearningRule(\n",
    "                    # dd='2^0*x0 - 2^3*u7*d',\n",
    "                    dt='2^0*y0 - 2^0*u7*t',\n",
    "                    dw=dw_hid,\n",
    "                    x1_impulse=1,\n",
    "                    x1_tau=hid_x1TimeConstant,\n",
    "                    y1_impulse=1,\n",
    "                    y1_tau=hid_y1TimeConstant,\n",
    "                    x2_impulse=1,\n",
    "                    x2_tau=64,\n",
    "                    t_epoch=1)\n",
    "            else:\n",
    "                # single update per sample\n",
    "                lr = Loihi2FLearningRule(\n",
    "                    # dd='2^0*x0 - 2^3*u7*d',\n",
    "                    dt='2^0*y0 - 2^0*u7*t',\n",
    "                    dw=dw_hid,\n",
    "                    x1_impulse=1,\n",
    "                    x1_tau=hid_x1TimeConstant,\n",
    "                    y1_impulse=1,\n",
    "                    y1_tau=hid_y1TimeConstant,\n",
    "                    x2_impulse=1,\n",
    "                    x2_tau=64,\n",
    "                    t_epoch=1)\n",
    "\n",
    "            if pIdx == 0:\n",
    "                # forWgts = np.ones((self.numHidNurns[pIdx], self.numMCs), int)*4\n",
    "                if len(wgt) == 0:\n",
    "                    forWgts = init_wgts(self.negwgtrng, self.poswgtrng, self.numHidNurns[pIdx], self.numMCs, pIdx)\n",
    "                    # forWgts = np.random.randint(low=self.negwgtrng, high=self.poswgtrng, size=(self.numHidNurns[pIdx], self.numMCs), dtype=int)\n",
    "                else:\n",
    "                    forWgts = self.hid_wgt\n",
    "\n",
    "                forConnGrp_1 = LearningDense(\n",
    "                    weights = forWgts,\n",
    "                    learning_rule= lr,\n",
    "                    name = 'input_hidden_conn'\n",
    "                    \n",
    "                )\n",
    "\n",
    "                self.forwardConns[pIdx] = forConnGrp_1\n",
    "                self.allMCSomaGrp.s_out.connect(forConnGrp_1.s_in)\n",
    "                forConnGrp_1.a_out.connect(self.allGCsPerPattern[pIdx].a_in)\n",
    "                #backward connecions\n",
    "                self.allGCsPerPattern[pIdx].s_out.connect(forConnGrp_1.s_in_bap)\n",
    "\n",
    "            else:\n",
    "                if len(wgt) == 0:\n",
    "                    forWgts = init_wgts(self.negwgtrng, self.poswgtrng, self.numHidNurns[pIdx],\n",
    "                                        self.numHidNurns[pIdx - 1], pIdx)\n",
    "                else:\n",
    "                    forWgts = self.out_wgt\n",
    "\n",
    "                #                 print(forWgts)\n",
    "\n",
    "                forConnGrp_2 = LearningDense(\n",
    "                    weights = forWgts,\n",
    "                    learning_rule= lr,\n",
    "                    name = 'hid_out_conn'\n",
    "                    \n",
    "                )\n",
    "\n",
    "                self.forwardConns[pIdx] = forConnGrp_2\n",
    "                self.allGCsPerPattern[pIdx-1].s_out.connect(forConnGrp_2.s_in)\n",
    "                forConnGrp_2.a_out.connect(self.allGCsPerPattern[pIdx].a_in)\n",
    "                #backward connections for the second layer\n",
    "                self.allGCsPerPattern[pIdx].s_out.connect(forConnGrp_2.s_in_bap)\n",
    "                \n",
    "    def connectbackwardConns(self, bwgt):\n",
    "        # connections for the error path\n",
    "        for pIdx in range(self.numlayers):\n",
    "\n",
    "            if pIdx == 0:\n",
    "                # self.backwardConns[pIdx] = self.net.createConnectionGroup()\n",
    "                self.posbackwardConns[pIdx] = []\n",
    "                self.negbackwardConns[pIdx] = []\n",
    "                self.posbackwardConns[pIdx + 1] = []\n",
    "                self.negbackwardConns[pIdx + 1] = []\n",
    "\n",
    "            elif pIdx == self.numlayers - 1:\n",
    "\n",
    "                if len(bwgt) == 0:\n",
    "                    # posbackWgts = init_wgts(self.negwgtrng, self.poswgtrng, self.numHidNurns[pIdx-1], self.numHidNurns[pIdx])\n",
    "                    posbackWgts = np.random.randint(low=self.bnegwgtrng, high=self.bposwgtrng,\n",
    "                                                    size=(self.numHidNurns[pIdx - 1], self.numHidNurns[pIdx]),\n",
    "                                                    dtype=int)\n",
    "                else:\n",
    "                    posbackWgts = bwgt[pIdx].T\n",
    "\n",
    "                negbackWgts = - posbackWgts\n",
    "\n",
    "                #error layer\n",
    "                # src: pos ec ->pos ec soma\n",
    "                # weights - posbackWgts\n",
    "                posECtoSomaConn = Dense(\n",
    "                    weights = posbackWgts\n",
    "                )\n",
    "                self.allPosECsPerPattern[pIdx].s_out.connect(posECtoSomaConn.s_in)\n",
    "                posECtoSomaConn.a_out.connect(self.pos_ec_soma.a_in)\n",
    "\n",
    "                #src: neg EC pidx -> dst: pos EC soma pidx -1\n",
    "                # negbackwgts\n",
    "\n",
    "                negECtpPosECsoma = Dense(\n",
    "                   weights = negbackWgts\n",
    "               )\n",
    "                self.allNegECsPerPattern[pIdx].s_out.connect(negECtpPosECsoma.s_in)\n",
    "                negECtpPosECsoma.a_out.connect(self.pos_ec_soma.a_in)\n",
    "\n",
    "                # src: neg ec Pidx -> dst neg ec pidx -1 soma\n",
    "                # weights = posbackWgts\n",
    "                negECtonegECsoma = Dense(\n",
    "                    weights = posbackWgts\n",
    "                )\n",
    "                self.allNegECsPerPattern[pIdx].s_out.connect(negECtonegECsoma.s_in)\n",
    "                negECtonegECsoma.a_out.connect(self.neg_ec_soma.a_in)\n",
    "\n",
    "                #src: posec pidx ->dst : negec soma \n",
    "                # weights negbacl wgts\n",
    "                posECtonegsoma = Dense(weights = negbackWgts\n",
    "                                       )\n",
    "                self.allPosECsPerPattern[pIdx].s_out.connect(posECtonegsoma.s_in)\n",
    "                posECtonegsoma.a_out.connect(self.neg_ec_soma.a_in)\n",
    "\n",
    "                '''\n",
    "                connect soma, dendrite to the final neuron\n",
    "                weight =10\n",
    "                '''\n",
    "                pos_soma_conn = Dense(\n",
    "                    weights = int(10)*np.eye(self.numHidNurns[pIdx-1])\n",
    "                )\n",
    "                pos_dendrite_conn = Dense(\n",
    "                    weights = int(10)**np.eye(self.numHidNurns[pIdx-1])\n",
    "                )\n",
    "\n",
    "                self.pos_ec_soma.s_out.connect(pos_soma_conn.s_in)\n",
    "                pos_soma_conn.a_out.connect(self.allPosECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "                self.pos_ec_dendrite.s_out.connect(pos_dendrite_conn.s_in)\n",
    "                pos_dendrite_conn.a_out.connect(self.allPosECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "                neg_soma_conn = Dense(\n",
    "                    weights = int(10)*np.eye(self.numHidNurns[pIdx-1])\n",
    "                )\n",
    "                neg_dendrite_conn = Dense(\n",
    "                    weights = int(10)**np.eye(self.numHidNurns[pIdx-1])\n",
    "                )\n",
    "\n",
    "                self.neg_ec_soma.s_out.connect(neg_soma_conn.s_in)\n",
    "                neg_soma_conn.a_out.connect(self.allNegECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "                self.neg_ec_dendrite.s_out.connect(neg_dendrite_conn.s_in)\n",
    "                neg_dendrite_conn.a_out.connect(self.allNegECsPerPattern[pIdx-1].a_in)\n",
    "\n",
    "\n",
    "            else:\n",
    "                '''\n",
    "                more than two learning layers\n",
    "                '''\n",
    "                print(\"to do: more than 3 hidden layers\")\n",
    "\n",
    "\n",
    "    def idxToBases(self, inputList):\n",
    "        \"\"\" maps the input data/sensor reading to an MC-AD bias current\"\"\"\n",
    "        # inputList = list(inputList)\n",
    "        # return [self.stim2bias[i] for i in inputList]\n",
    "        return inputList\n",
    "\n",
    "    def generate_data(self,train_data):\n",
    "        '''\n",
    "        train_data shape: N,200\n",
    "        '''\n",
    "        for i in range(len(train_data)):\n",
    "            #arange train data\n",
    "            self.train_data.append(self.idxToBases(train_data[0][i]))\n",
    "\n",
    "    '''\n",
    "    define probes for the network\n",
    "    ''' \n",
    "    def probes(self,num_img=1):\n",
    "        out_spikes = Monitor()\n",
    "        out_spikes.probe(self.allGCsPerPattern[-1].s_out,self.num_steps*num_img)\n",
    "\n",
    "        return out_spikes\n",
    "    \n",
    "    #set up training parameters \n",
    "    def set_label_para(self,label):\n",
    "        #set up label data to the label layer\n",
    "        self.allLabelGrp.bias_mant.set(label)\n",
    "\n",
    "    #reset some traces probes\n",
    "    def reset_traces(self):\n",
    "        '''\n",
    "        # # Learning Vars\n",
    "        # self.x0 = Var(shape=(shape[-1],), init=0)\n",
    "        # self.tx = Var(shape=(shape[-1],), init=0)\n",
    "        # self.y0 = Var(shape=(shape[0],), init=0)\n",
    "        # self.ty = Var\n",
    "        # '''\n",
    "        for i in range(self.numlayers):\n",
    "            self.forwardConns[i].x0 .set(np.zeros((self.forwardConns[i].weights.shape[-1],)).astype(int))\n",
    "            self.forwardConns[i].tx.set(np.zeros((self.forwardConns[i].weights.shape[-1],)).astype(int))\n",
    "            self.forwardConns[i].y0.set(np.zeros((self.forwardConns[i].weights.shape[0],)).astype(int))\n",
    "            self.forwardConns[i].ty.set(np.zeros((self.forwardConns[i].weights.shape[0],)).astype(int))\n",
    "\n",
    "    #reset some gc u and v\n",
    "    def reset_gc(self):\n",
    "        for i in range(self.numlayers):\n",
    "            self.allGCsPerPattern[i].u.set(np.zeros((self.numHidNurns[i]),).astype(int))\n",
    "            self.allGCsPerPattern[i].v.set(np.zeros((self.numHidNurns[i]),).astype(int))\n",
    "            \n",
    "    #Reset EC layers\n",
    "    def reset_ec(self,reset_mode = 0):\n",
    "        #if reset mode ==1, means training. set v and u to normal value\n",
    "        for i in range(self.numlayers):\n",
    "            if reset_mode:\n",
    "                self.allNegECsPerPattern[i].set_dv(np.zeros((1,)))\n",
    "                self.allPosECsPerPattern[i].set_dv(np.zeros((1,)))\n",
    "\n",
    "                self.allNegECsPerPattern[i].set_vth(int(8*2**6)*np.ones((1,)))\n",
    "                self.allPosECsPerPattern[i].set_vth(int(8*2**6)*np.ones((1,)))\n",
    "            else:\n",
    "                self.allNegECsPerPattern[i].set_dv(4095*np.ones((1,)))\n",
    "                self.allPosECsPerPattern[i].set_dv(4095*np.ones((1,)))\n",
    "\n",
    "                self.allNegECsPerPattern[i].set_vth(int(3255*2**6)*np.ones((1,)))\n",
    "                self.allPosECsPerPattern[i].set_vth(int(3255*2**6)*np.ones((1,)))\n",
    "\n",
    "\n",
    "    '''\n",
    "    set up another network to do the inference\n",
    "    '''\n",
    "\n",
    "    def test(self,imgs,hid_wgt = [] , out_wgt = [] ,num_steps = 128):\n",
    "        #create connections\n",
    "        #reconstruct input:\n",
    "        self.createTestInputs()\n",
    "        for patternIdx in range(self.numlayers):\n",
    "            self.createTestGC(patternIdx= patternIdx)\n",
    "        if len(hid_wgt) ==0:\n",
    "            hid_weights = self.hid_wgt\n",
    "            out_weights = self.out_wgt\n",
    "        else:\n",
    "            hid_weights = hid_wgt\n",
    "            out_weights = out_wgt\n",
    "            \n",
    "        self.test_inter = Dense(\n",
    "            weights = hid_weights\n",
    "        )\n",
    "        self.test_out = Dense(\n",
    "            weights = out_weights\n",
    "        )\n",
    "        # first layer connection\n",
    "        self.inputs.s_out.connect(self.test_inter.s_in)\n",
    "        self.test_inter.a_out.connect(self.hiddens[0].a_in)\n",
    "        # second layer connection\n",
    "        self.hiddens[0].s_out.connect(self.test_out.s_in)\n",
    "        self.test_out.a_out.connect(self.hiddens[1].a_in)\n",
    "\n",
    "        #probes for the spikes\n",
    "        out_probe = Monitor()\n",
    "        out_probe.probe(self.hiddens[1].s_out, 1+len(imgs)*num_steps)\n",
    "        self.inputs.run(condition=RunSteps(num_steps= 1), run_cfg=Loihi2HwCfg(\n",
    "            select_tag = SELECT_TAG\n",
    "        ))\n",
    "        # running test cases\n",
    "        for i in range(len(imgs)):\n",
    "            #converting img input to integer\n",
    "            img = imgs[i]\n",
    "            self.inputs.bias_mant.set(img)\n",
    "            #running the network\n",
    "            self.inputs.run(condition=RunSteps(num_steps= num_steps), run_cfg=Loihi2HwCfg(\n",
    "            select_tag = SELECT_TAG\n",
    "        ))\n",
    "            \n",
    "        spikes = out_probe.get_data()[self.hiddens[1].name]['s_out']\n",
    "        self.inputs.stop()\n",
    "        result = np.zeros((len(imgs),10))\n",
    "        for j in range(len(imgs)):\n",
    "            tmp = np.sum(spikes[j*(num_steps):(j+1)*num_steps,:],axis =0)\n",
    "            result[j,:] = tmp\n",
    "        print(result)\n",
    "        res = np.argmax(result,axis =-1)\n",
    "\n",
    "        return res\n",
    "        \n",
    "    '''\n",
    "    t =0 : send initialized data\n",
    "    t = 1: reset, apply labels\n",
    "    t = 2: apply input\n",
    "    '''\n",
    "    def fit(self,imgs,labels,num_steps=128):\n",
    "        '''\n",
    "        run for just one time step, for the bias setting purpose\n",
    "        '''\n",
    "        # hid_wgt,out_wgt = self.weight_probe(img)\n",
    "        probe = Monitor()\n",
    "        probe.probe(self.allGCsPerPattern[1].s_out,1+len(imgs)*128)\n",
    "        self.allMCSomaGrp.run(condition=RunSteps(num_steps= 1), run_cfg=Loihi2HwCfg(\n",
    "            select_tag = SELECT_TAG\n",
    "        ))\n",
    "        '''\n",
    "        set up probes\n",
    "        '''\n",
    "        for i in range(len(imgs)):\n",
    "            train = False\n",
    "            '''\n",
    "            reset all forward layers intermediate values\n",
    "            '''\n",
    "\n",
    "            '''\n",
    "            set up input data to bias\n",
    "            set up label layer parameters\n",
    "            '''\n",
    "            img = imgs[i]\n",
    "            '''\n",
    "            Reset GC, Reset EC neurons\n",
    "            '''\n",
    "            self.allMCSomaGrp.bias_mant.set(img)\n",
    "            self.set_label_para(labels[i])\n",
    "            self.reset_ec()\n",
    "            self.reset_gc()\n",
    "           \n",
    "            #set labels\n",
    "            # run first 64 timesteps:\n",
    "            self.allMCSomaGrp.run(condition=RunSteps(num_steps= num_steps//2), run_cfg=Loihi2HwCfg(\n",
    "                    select_tag = SELECT_TAG))\n",
    "            '''\n",
    "            Reset GCs, ECS\n",
    "            '''\n",
    "            #self.set_label_para(labels[i])\n",
    "            self.reset_gc()\n",
    "            self.allGCsPerPattern[1].set_vth(4095*np.ones((1,)))\n",
    "            self.reset_ec(reset_mode=1)\n",
    "            '''\n",
    "            Reset learning traces\n",
    "            '''\n",
    "            self.reset_traces()\n",
    "            \n",
    "\n",
    "            self.allMCSomaGrp.run(condition=RunSteps(num_steps= num_steps//2), run_cfg=Loihi2HwCfg(select_tag= SELECT_TAG))\n",
    "            '''\n",
    "            Uncomment it if you need the dynamics of the weight.\n",
    "            '''\n",
    "            # hid_wgt.get_data()['input_hid_conn']['weights'][-1]\n",
    "            # out_wgt.get_data()['hid_out_conn']['weights'][-1]\n",
    "        self.hid_wgt = self.forwardConns[0].weights.get()\n",
    "        self.out_wgt = self.forwardConns[1].weights.get()\n",
    "        spikes = probe.get_data()[self.allGCsPerPattern[1].name]['s_out']\n",
    "        self.allMCSomaGrp.stop()\n",
    "        #print non zero elements\n",
    "        #print(np.count_nonzero(spikes))\n",
    "        spikes = spikes[1:]\n",
    "        result = np.zeros((len(imgs),10))\n",
    "        for j in range(len(imgs)):\n",
    "            tmp = np.sum(spikes[j*(num_steps):(j+1)*num_steps,:],axis =0)\n",
    "            result[j,:] = tmp\n",
    "        print(result[-10:])\n",
    "        res = np.argmax(result,axis =-1)\n",
    "        #print the last 10 spiking results\n",
    "        print(res[-10])\n",
    "        # #saving weigt\n",
    "        np.save(\"hid_wgt\",self.hid_wgt)\n",
    "        np.save(\"out_wgt\",self.out_wgt)\n",
    "\n",
    "        #return weights\n",
    "    def weights(self):\n",
    "        return self.hid_wgt, self.out_wgt \n",
    "\n",
    "#Here is the example usage of the testing cases\n",
    "network = emstdp()\n",
    "#setup network\n",
    "network.setupNetwork(True,[],[])\n",
    "\n",
    "#testing data\n",
    "imgs = np.load(\"x_train.npy\")\n",
    "labels = np.load(\"y_train.npy\")\n",
    "imgs = imgs/np.max(imgs)\n",
    "#construct the single imgs set\n",
    "train_data = np.zeros((100,200))\n",
    "train_label = np.zeros((100,10))\n",
    "imgs = (1*256*imgs).astype(int)\n",
    "# train_data = imgs[:100]\n",
    "# train_lable = labels[:100]\n",
    "for i in range(100):\n",
    "    train_data[i] = imgs[5]\n",
    "    train_label[i] = labels[5]\n",
    "    idx = np.argmax(labels[5])\n",
    "    train_label[i,idx] = 128\n",
    "\n",
    "test_data = train_data[:2]\n",
    "print(train_label.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0ca46ac-5e32-404b-922b-0a1e42190722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time 1709051531.795515\n",
      "[[ 0.  0. 19.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 18.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 19.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 19.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 19.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 19.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 18.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 19.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 19.  0.  2.  0.  0.  2.  0.  0.]\n",
      " [ 0.  0. 20.  0.  2.  0.  1.  2.  0.  0.]]\n",
      "2\n",
      "elapsed time:  179.38822865486145\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(\"start time\",start)\n",
    "network.fit(imgs = train_data,labels=train_label)\n",
    "#test network \n",
    "end = time.time()\n",
    "print(\"elapsed time: \", end -start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6648d055-4329-4a06-aae6-2e5a9b92bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethreshold = \n",
      "8\n",
      "[[3. 1. 2. 0. 0. 2. 2. 2. 1. 1.]\n",
      " [3. 2. 2. 0. 0. 2. 2. 2. 2. 0.]]\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "in_wgt = np.load(\"hid_wgt.npy\")\n",
    "out_wgt = np.load(\"out_wgt.npy\")\n",
    "result = network.test(test_data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07477a1c-552a-487e-9b35-492809b50d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(labels[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00650f-d241-491c-90c9-cdb67b5452d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
